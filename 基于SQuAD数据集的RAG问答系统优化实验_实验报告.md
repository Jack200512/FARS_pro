作者：卢满江 
学号：202430551043 
班级：24软件工程1班  
日期：2025年8月12日

## 一、项目背景与目标

本项目在问答任务中采用 SQuAD数据集进行评测。尽管当前生成式模型在部分任务中能够给出合理答案，但在处理长文本、细粒度信息或跨段落推理等场景时，仍存在知识覆盖不足、推理链不完整等局限。RAG 模式通过在生成阶段前引入基于检索的相关文档，将外部知识动态融入生成过程，从而显著提升答案的准确性、可靠性与覆盖范围，尤其适用于开放域问答和知识密集型任务

项目主要目标包括：

1. **构建基于检索增强生成范式的问答系统
2. **系统性比较多样检索策略的性能表现**
3. **基于标准数据集进行量化性能评测
4. **调节检索模块和生成模块的关键参数，实现问答系统的性能优化

通过本项目，期望夯实检索增强生成系统的构建与优化能力，为今后深入自然语言处理领域的研究与应用奠定坚实基础。

## 二、实验环境

- 平台：Kaggle
- GPU：Tesla T4 / 15GB
- Python版本：3.11

## 三、数据集与评测相关说明

- #### 原始数据集：SQuAD
	- SQuAD（Stanford Question Answering Dataset）是一个广泛应用于自然语言处理领域的机器阅读理解数据集，包含维基百科文章的段落及其对应的问答对。
	- 在本项目中，SQuAD训练集被用作*静态知识库*，通过检索相关段落为生成模型提供精准上下文，从而提升问答系统在回答问题时的准确性和可靠性。

- #### 评测方法：SQuAD官方评测程序
	- **Exact Match**指标：计算模型答案与标准答案完全一致的比例。
	- **F1 分数**： 衡量模型答案与标准答案词级重叠的综合准确度。

- #### 评测范围：SQuAD dev set的前500个问题

## 四、技术路线与整体框架

- 系统整体架构基于检索增强生成（RAG）流程，主要包括三个核心模块。关键程序流程如下：首先，检索模块负责从预先构建的知识库中筛选与问题最相关的文档或文本片段；其次，生成模块将检索到的上下文与问题结合，利用生成式语言模型生成答案；最后，评测模块采用标准化指标对生成结果进行性能评价，确保系统整体效果的科学可靠。

## 五、检索模块优化相关

1. **检索框架的演进**
	- **Faiss CPU IVF索引**：最初采用Faiss CPU版IVF索引对上下文向量聚类分区，实现近似向量检索，降低查询时间，但存在训练耗时长、CPU性能瓶颈和精度损失，后续逐步弃用。
	- **纯向量内积相似度计算**：转为直接计算所有上下文与查询向量的内积相似度，无索引结构，保证检索精度，但计算量大，性能受限。
	- **GPU加速编码与批处理**：将向量编码迁移至GPU批量执行，大幅缩短嵌入时间，查询向量转CPU计算相似度，提升整体检索效率。

2. **检索策略**
    - 初期采用纯句向量内积相似度计算，实现基于语义的文本匹配。
    - 后期引入BM25与句向量的混合加权方案，结合词频统计与语义向量相似度，提升检索的准确性。

3. **检索参数调优**
	- **Top-K召回数量调整**  
	    通过调节Top-K的取值，控制候选文本数量，权衡检索召回的全面性与计算资源消耗，避免过多无关内容影响后续生成效率。
	- **加权系数优化**  
	    针对BM25得分与句向量相似度在混合检索中的权重分配，进行系统调整，以实现更合理的排序结果，提升检索相关性和问答准确率。
	- **参数调优效果评估**  
	    结合实际问答性能指标（Exact Match和F1分数）反馈，持续优化以上参数，确保检索模块在不同配置下达到最优性能。

## 六、生成模块优化相关

1. **生成模型演进**
	- 初期采用基于decoder的生成模型如Opt 2，侧重单向语言建模
	- 后期切换至Seq2Seq架构如Flan-T5系列，增强编码器-译码器协同，提高对上下文理解与生成的质量，取得成绩方面的进步。

2. **生成参数调优**
	- 通过调整Beam Search宽度，探索“搜索空间”大小对生成质量的影响
	- 试验不同的温度参数Temperature，平衡生成多样性与确定性
	- 设定最大生成长度，控制回答的完整性与生成效率

## 七、双端调参分析

#### 1.检索端

- 调节“候选上下文数量Top-K”与“句向量相似度过滤阈值Threshold”，观察指标变化。

| Top-K | 相似度阈值 | Exact | F1    | Total |
| ----- | ----- | ----- | ----- | ----- |
| 3     | None  | 18.40 | 20.44 | 500   |
| 3     | 0.6   | 19.60 | 21.64 | 500   |
| 2     | 0.3   | 34.80 | 36.46 | 500   |
| 2     | 0.6   | 35.40 | 36.93 | 500   |
| 2     | 0.5   | 35.60 | 37.13 | 500   |
| 2     | 0.4   | 35.80 | 37.46 | 500   |
| 1     | 0.6   | 44.60 | 45.79 | 500   |
| 1     | 0.5   | 44.60 | 45.79 | 500   |
| 1     | 0.4   | 44.60 | 45.79 | 500   |
| 1     | 0.3   | 44.60 | 45.79 | 500   |
| 1     | 0.2   | 44.60 | 45.79 | 500   |

#### 规律总结
- **Top-K 减小显著提升性能**  
	- Top-K 从 3 到 1 下降时，EM/F1 升至最高（44.60%/45.79%），因单一上下文减少噪声。  
- **Top-K=1 时性能稳定**  
	- Top-K=1 下，所有阈值 EM/F1 恒定，阈值影响最小。  
- **阈值对 Top-K>1 有优化作用**  
    - Top-K=2/3 时，阈值 0.4–0.5 最佳（EM/F1 略升），平衡候选质量与数量。  
- **阈值对 Top-K=1 无影响**  
	- Top-K=1 只取最高分上下文，阈值仅滤候选池但不改最终输出。  
- **Top-K 与阈值交互效应明显**  
	- Top-K 越大，阈值作用越强（高阈值滤噪声），Top-K 小则阈值无关。

#### 分析
- 表格显示，Top-K从3降至1时，精确匹配率（EM）和F1分数显著提升，从18-19%跃升至44.6%，这可能因为单一高相关上下文减少了噪声，避免生成模型（FLAN-T5）因无关或冗余信息而产生偏差。对于相似度阈值，当Top-K=2或3时，阈值0.4-0.5略微提升性能（EM提升约1%），表明该范围平衡了候选质量与数量的筛选。然而，阈值过高（如0.6）导致性能略降，可能是因为过度过滤丢弃了潜在相关片段，尤其在BM25初筛（top_n=5）已提供多样候选的情况下。当Top-K=1时，阈值0.2至0.6的结果一致，说明BM25与句向量嵌入已确保最高相关上下文被选中，阈值影响被弱化。这表明Top-K=1搭配适中阈值（如0.3）能最大化效率与精度。

### 2.生成端

调节“生成模块接受上下文数量Top-N” 、”束搜索宽度Beam“与”最大生成长度Max Tokens“，观察指标变化情况

| Top-N | Beam | Max Tokens | Exact | F1    | 测试样本数 |
| ----- | ---- | ---------- | ----- | ----- | ----- |
| 6     | 2    | 64         | 47.80 | 48.20 | 500   |
| 3     | 5    | 16         | 47.80 | 48.08 | 500   |
| 1     | 5    | 16         | 47.80 | 48.00 | 500   |
| 1     | 8    | 16         | 48.00 | 48.20 | 500   |
| 4     | 2    | 64         | 48.20 | 48.50 | 500   |
| 4     | 2    | 16         | 48.20 | 48.50 | 500   |
| 4     | 3    | 64         | 48.80 | 49.08 | 500   |
| 4     | 3    | 16         | 48.80 | 49.08 | 500   |

#### 规律总结
- **Top-N=4 性能最佳**
    - Top-N=4（EM=48.80%, F1=49.08% at Beam=3）优于Top-N=1或6，平衡上下文多样性与噪声。
- **Beam增大，成绩提升**
    - Beam=3（EM=48.80%）或8（EM=48.00%）优于Beam=2，更多生成路径提升答案质量，但耗时增加。
- **Max Tokens 影响甚微**
    - Max Tokens=16与64结果一致（EM=48.20–48.80%），16已够覆盖SQuAD短答案。
- **Top-N 与 Beam 交互明显**
    - Top-N=4配Beam=3最佳，Top-N=1需Beam=8补足，上下文量影响Beam需求。

#### 分析
- 生成端参数调节结果显示，适度增加束宽度（Beam）从2至3能够提升模型的精确匹配率和F1分数，帮助生成模型探索更多可能答案，从而提高回答质量；但束宽度继续增大未带来显著提升，且增加计算开销。最大生成长度（Max Tokens）在16与64之间的变化对性能影响有限，表明较短的生成长度已能满足大部分问答需求，避免了冗余信息产生。检索候选上下文数（Top-N）对生成效果影响明显，过多上下文反而可能增加生成难度，导致性能下降。整体来看，生成端应保持适中束宽度与生成长度，结合合理的Top-N值，以实现性能与效率的最佳平衡。

## 八、问答性能优化历程

初始成绩 E 2.20 / F 3.25

- ##### 弃用faiss， 引入纯向量内积相似度计算方法
	- *成绩E 2.40 / F 4.05
	- 最初使用FAISS的IVF索引虽然检索速度快，但因为是近似搜索，可能漏掉一些相关内容。后来改用纯向量内积计算，虽然计算量大，但能更准确找到相关上下文，所以成绩有了小幅提升。

- ##### 更换生成模型，Flan T5 base => Flan T5 xl
	- *成绩E 2.80 / F 5.54
	- 模型拥有更多参数和更强的表达能力，能够更准确理解和结合检索到的上下文信息，从而生成更精准、流畅的答案。但K值仍较高，干扰信息多，限制发挥，故进步微小。

- ##### 调节检索端Top K = 1，threshold = 0.3
	- *成绩==E 44.60 / F 45.79==
	- 性能显著提升，减少了上下文数量，从而有效降低了无关或冗余信息对生成模型的干扰，使得模型能够更专注于最相关的内容进行回答生成。这种聚焦提升了答案的准确性和一致性，导致 Exact Match 和 F1 分数大幅度提升。

- ##### 选择BM25+Hybrid Search检索策略
	- *成绩E 46.60 / F 46.94
	- 采用BM25与句向量混合的检索策略带来小幅性能提升，主要因为BM25能够有效捕捉关键词匹配信息，补充纯向量检索在某些细节上的不足。混合策略结合了词频统计和语义相似度，增强了候选上下文的相关性和多样性，从而略微提高了问答的准确率和召回效果。

- ##### BM25-TopN = 4 ，Beam = 8，max tokens = 16
	- *成绩E 52.20 / F 52.41
	- 降低检索阶段返回的候选上下文数量，从而减少了输入给生成模型的信息噪声，使生成模型能够更专注于最相关的内容，避免因无关或冗余信息干扰而产生偏差；同时，调大 Beam Search 宽度提升了生成过程的搜索能力，使模型在解码时能探索更多高质量的答案候选路径，增强了答案的准确性和多样性。两者协同作用，有效提升了问答性能。

性能提升关键：
- 检索端减小上下文噪声干扰
- 生成端优化束搜索宽度

## 九、总结与反思
### 1.实验成果

本实验最终在 Kaggle 硬件限制下，实现了 **Exact Match 52.20 / F1 52.41** 的成绩，相较初始版本（E 2.20 / F 4.05）提升近 50 个百分点。性能提升主要得益于三方面：其一，检索端精简上下文（Top-K 从 3 降至 1），显著减少了无关信息干扰；其二，引入 BM25+向量混合检索策略，兼顾关键词匹配与语义相似度，提高了候选片段的相关性；其三，生成端调大 Beam 宽度至 8，并合理控制 max tokens，增强了答案生成的搜索深度与多样性。整个优化过程未依赖额外硬件，而是通过算法与参数调整，在有限资源下实现了稳定且较大幅度的性能提升，为资源受限环境下的 RAG 系统优化提供了可复用的参考方案。

### 2.遇上的问题与解决方案

在实验的过程中遇到一些问题，通过查阅资料与询问AI都得到了较好的解决

1. **预测数据与评测数据不完全重合**
	- 在实验初期，由于硬件资源的限制，无法在推理阶段处理完整的dev集，而是选择前500个问题进行预测。然而，最终评测却基于完整的dev集进行计算。这导致了模型调参过程中观察到的与真实的成绩存在较大偏差，降低了实验反馈的准确性。
	- **解决方法**：严格限定只预测前500个问题，只评测前500个问题的回答情况。

2. **CPU Faiss检索时间长，成为性能瓶颈**
	- 最初采用基于 CPU 的 FAISS IVF 索引进行相似度检索，虽然支持大规模向量存储与近似搜索，但存在计算开销大、耗时长的问题，尤其在多轮调参与全量推理阶段，检索成为系统性能瓶颈。
	- **解决方法**：弃用 FAISS IVF 索引，改为利用 GPU 进行纯向量内积相似度计算，充分利用 GPU 并行计算能力，加速批量向量比对过程，缩短检索耗时，同时在一定程度上提升了检索精度。

3. **对参数含义理解不足导致调参方向模糊**
	- 实验初期对关键超参数（如Top-K、相似度阈值、Beam宽度、max tokens 等）的内涵理解不够深入，因而在调参时缺乏明确的方向，容易进行盲目或低效的尝试，浪费计算资源并延长迭代周期。
	- **解决方法**：采用分阶段系统化探索策略：首先通过“多路小步走”方式对各类参数进行粗粒度扫描（如 Top-K ∈ {1,2,3,4,6}，Beam ∈ {2,3,5,8}，threshold ∈ {0.2,0.4,0.6}），快速锁定表现较优的区间；随后利用单因子试验法，在保持其他参数不变的情况下逐一调整单个参数，明确其独立影响；最后在优良区间内进行细粒度网格搜索，精确定位性能拐点或最优值，从而建立了清晰的调参路径并显著提升了实验效率。

### 3.不足之处

虽然本实验已经在资源受限的情况下取得了较为理想的结果，但仍然存在以下不足之处。

- 基础理论知识仍较为薄弱，项目开发和优化过程中较多依赖AI辅助，缺少对核心算法和模型运行机制的深入理解，导致对代码实现细节及整体架构的认知较为表层，影响对问题本质的把握与解决。
    
- 对关键参数的含义及其相互作用理解不充分，特别是在生成模块与检索模块的配合关系上认识模糊，缺乏系统的参数调优思路，难以高效指导模型性能提升。
    
- 未尝试在生成模型上进行微调或预训练，直接使用预训练模型与RAG框架结合，错失了通过微调提升模型适应性和问答性能的机会。
    
- 优化过程中进行了多次试错和低效调整，缺少明确的优化策略和方向，导致资源浪费和时间延长，未能快速定位和落实有效的提升方案。
    
- 工程实践意识不足，有时未及时记录实验的修改更新内容及其对性能的影响，导致后期回顾时对优化效果和原因分析存在较大困难，影响整体项目管理与复现。
    

### 4.未来计划

针对仍然存在的不足之处，未来规划主要聚焦于如下几个方面：

- **深化理论基础学习**
    - 系统学习信息检索和生成模型的核心原理，理解底层机制。
    - 重点掌握向量检索、BM25等检索算法的数学基础及优缺点。
    - 通过阅读论文、官方文档和经典教程，提高对模型内部运行流程和关键技术点的理解。
    - 尝试独立完成代码开发工作，加深对代码实践的理解。

- **建立科学的参数调优体系**
    - 梳理检索端和生成端的关键参数及其影响（如Top-K、相似度阈值、Beam宽度、最大生成长度等）。
    - 制定系统化的参数调优流程，进一步充分利用分阶段调参策略提升调参效率。
    - 设计更加高效的调参实验，记录每次参数变化对应的性能指标，形成经验库。

- **尝试生成模型微调与定制化训练**
    - 尝试结合微调技术，增强模型对任务特定领域的适应性。
    - 评估微调后的模型与RAG框架结合的效果，寻找性能提升空间。
        
- **优化实验设计与路径规划**
    - 制定清晰的实验计划，避免盲目尝试和重复劳动。
    - 每次优化均明确目标、设计对照组，确保实验数据的有效性和可比性。
    - 结合性能趋势和资源情况，优先推进高效、易落地的优化方向。
        
- **强化工程规范与管理**
    - 规范代码版本管理和实验日志，确保每次变更和结果均有详细记录。
    - 建立完整的文档体系，包括参数说明、实验步骤和结果分析，方便团队协作和后续复现。
